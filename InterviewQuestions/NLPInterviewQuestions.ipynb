{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c1af2e3",
   "metadata": {},
   "source": [
    "## Given a string of text, write a function to extract all the email addresses from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a6fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b87ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email_address(text):\n",
    "    pattern = r'\\w+\\@\\w+(?:\\.\\w+)+'\n",
    "    \n",
    "    matches = re.findall(pattern,text)\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1be1d89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['email@abc.com']\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Hello my id is email@abc.com and phone is 8002003001\"\n",
    "email = extract_email_address(sample_text)\n",
    "print(email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2872074",
   "metadata": {},
   "source": [
    "## Write a python program to extract all the URLs from a webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81de1d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ded354de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_urls(url):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    links = soup.find_all('a') # find everything from the <a> anchor tags in html \n",
    "    \n",
    "    urls = []\n",
    "    for link in links:\n",
    "        if 'href' in link.attrs:\n",
    "            urls.append(link.attrs['href'])\n",
    "\n",
    "    return urls\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe04c3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#bodyContent', '/wiki/Main_Page', '/wiki/Wikipedia:Contents', '/wiki/Portal:Current_events', '/wiki/Special:Random', '/wiki/Wikipedia:About', '//en.wikipedia.org/wiki/Wikipedia:Contact_us', 'https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en', '/wiki/Help:Contents', '/wiki/Help:Introduction', '/wiki/Wikipedia:Community_portal', '/wiki/Special:RecentChanges', '/wiki/Wikipedia:File_upload_wizard', '/wiki/Main_Page', '/wiki/Special:Search', '/w/index.php?title=Special:CreateAccount&returnto=Data+science', '/w/index.php?title=Special:UserLogin&returnto=Data+science', '/w/index.php?title=Special:CreateAccount&returnto=Data+science', '/w/index.php?title=Special:UserLogin&returnto=Data+science', '/wiki/Help:Introduction', '/wiki/Special:MyContributions', '/wiki/Special:MyTalk', '#', '#Foundations', '#Relationship_to_statistics', '#Etymology', '#Early_usage', '#Modern_usage', '#See_also', '#References', 'https://ar.wikipedia.org/wiki/%D8%B9%D9%84%D9%85_%D8%A7%D9%84%D8%A8%D9%8A%D8%A7%D9%86%D8%A7%D8%AA', 'https://az.wikipedia.org/wiki/Veril%C9%99nl%C9%99r_elmi_(Data_Science)', 'https://bn.wikipedia.org/wiki/%E0%A6%89%E0%A6%AA%E0%A6%BE%E0%A6%A4%E0%A7%8D%E0%A6%A4_%E0%A6%AC%E0%A6%BF%E0%A6%9C%E0%A7%8D%E0%A6%9E%E0%A6%BE%E0%A6%A8', 'https://bg.wikipedia.org/wiki/%D0%9D%D0%B0%D1%83%D0%BA%D0%B0_%D0%B7%D0%B0_%D0%B4%D0%B0%D0%BD%D0%BD%D0%B8%D1%82%D0%B5', 'https://ca.wikipedia.org/wiki/Ci%C3%A8ncia_de_les_dades', 'https://cs.wikipedia.org/wiki/Data_science', 'https://de.wikipedia.org/wiki/Data_Science', 'https://et.wikipedia.org/wiki/Andmeteadus', 'https://el.wikipedia.org/wiki/%CE%95%CF%80%CE%B9%CF%83%CF%84%CE%AE%CE%BC%CE%B7_%CE%B4%CE%B5%CE%B4%CE%BF%CE%BC%CE%AD%CE%BD%CF%89%CE%BD', 'https://es.wikipedia.org/wiki/Ciencia_de_datos', 'https://eo.wikipedia.org/wiki/Datuma_scienco', 'https://eu.wikipedia.org/wiki/Datu_zientzia', 'https://fa.wikipedia.org/wiki/%D8%B9%D9%84%D9%85_%D8%AF%D8%A7%D8%AF%D9%87%E2%80%8C%D9%87%D8%A7', 'https://fr.wikipedia.org/wiki/Science_des_donn%C3%A9es', 'https://ko.wikipedia.org/wiki/%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%82%AC%EC%9D%B4%EC%96%B8%EC%8A%A4', 'https://hy.wikipedia.org/wiki/%D5%8F%D5%BE%D5%B5%D5%A1%D5%AC%D5%B6%D5%A5%D6%80%D5%AB_%D5%A3%D5%AB%D5%BF%D5%B8%D6%82%D5%A9%D5%B5%D5%B8%D6%82%D5%B6', 'https://hi.wikipedia.org/wiki/%E0%A4%86%E0%A4%81%E0%A4%95%E0%A4%A1%E0%A4%BC%E0%A4%BE_%E0%A4%B5%E0%A4%BF%E0%A4%9C%E0%A5%8D%E0%A4%9E%E0%A4%BE%E0%A4%A8', 'https://id.wikipedia.org/wiki/Ilmu_data', 'https://it.wikipedia.org/wiki/Scienza_dei_dati', 'https://he.wikipedia.org/wiki/%D7%9E%D7%93%D7%A2_%D7%94%D7%A0%D7%AA%D7%95%D7%A0%D7%99%D7%9D', 'https://kn.wikipedia.org/wiki/%E0%B2%A6%E0%B2%A4%E0%B3%8D%E0%B2%A4%E0%B2%BE%E0%B2%82%E0%B2%B6_%E0%B2%B5%E0%B2%BF%E0%B2%9C%E0%B3%8D%E0%B2%9E%E0%B2%BE%E0%B2%A8', 'https://kk.wikipedia.org/wiki/%D0%94%D0%B5%D1%80%D0%B5%D0%BA%D1%82%D0%B5%D1%80_%D1%82%D1%83%D1%80%D0%B0%D0%BB%D1%8B_%D2%93%D1%8B%D0%BB%D1%8B%D0%BC', 'https://lv.wikipedia.org/wiki/Datu_m%C4%81c%C4%ABba', 'https://mk.wikipedia.org/wiki/%D0%9D%D0%B0%D1%83%D0%BA%D0%B0_%D0%B7%D0%B0_%D0%BF%D0%BE%D0%B4%D0%B0%D1%82%D0%BE%D1%86%D0%B8%D1%82%D0%B5', 'https://ms.wikipedia.org/wiki/Sains_data', 'https://my.wikipedia.org/wiki/%E1%80%A1%E1%80%81%E1%80%BB%E1%80%80%E1%80%BA%E1%80%A1%E1%80%9C%E1%80%80%E1%80%BA%E1%80%9E%E1%80%AD%E1%80%95%E1%80%B9%E1%80%95%E1%80%B6%E1%80%95%E1%80%8A%E1%80%AC', 'https://nl.wikipedia.org/wiki/Datawetenschap', 'https://ja.wikipedia.org/wiki/%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9', 'https://no.wikipedia.org/wiki/Datavitenskap', 'https://uz.wikipedia.org/wiki/Ma%27lumotlar_ombori', 'https://pl.wikipedia.org/wiki/Danologia', 'https://pt.wikipedia.org/wiki/Ci%C3%AAncia_de_dados', 'https://qu.wikipedia.org/wiki/Willakuy_hamut%27ay', 'https://ru.wikipedia.org/wiki/%D0%9D%D0%B0%D1%83%D0%BA%D0%B0_%D0%BE_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85', 'https://simple.wikipedia.org/wiki/Data_science', 'https://fi.wikipedia.org/wiki/Datatiede', 'https://ta.wikipedia.org/wiki/%E0%AE%A4%E0%AE%B0%E0%AE%B5%E0%AF%81_%E0%AE%85%E0%AE%B1%E0%AE%BF%E0%AE%B5%E0%AE%BF%E0%AE%AF%E0%AE%B2%E0%AF%8D', 'https://th.wikipedia.org/wiki/%E0%B8%A7%E0%B8%B4%E0%B8%97%E0%B8%A2%E0%B8%B2%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B8%82%E0%B9%89%E0%B8%AD%E0%B8%A1%E0%B8%B9%E0%B8%A5', 'https://tr.wikipedia.org/wiki/Veri_bilimi', 'https://uk.wikipedia.org/wiki/%D0%9D%D0%B0%D1%83%D0%BA%D0%B0_%D0%BF%D1%80%D0%BE_%D0%B4%D0%B0%D0%BD%D1%96', 'https://ur.wikipedia.org/wiki/%DA%88%DB%8C%D9%B9%D8%A7_%D8%B3%D8%A7%D8%A6%D9%86%D8%B3', 'https://vi.wikipedia.org/wiki/Khoa_h%E1%BB%8Dc_d%E1%BB%AF_li%E1%BB%87u', 'https://zh-yue.wikipedia.org/wiki/%E6%95%B8%E6%93%9A%E7%A7%91%E5%AD%B8', 'https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6', 'https://www.wikidata.org/wiki/Special:EntityPage/Q2374463#sitelinks-wikipedia', '/wiki/Data_science', '/wiki/Talk:Data_science', '/wiki/Data_science', '/w/index.php?title=Data_science&action=edit', '/w/index.php?title=Data_science&action=history', '/wiki/Data_science', '/w/index.php?title=Data_science&action=edit', '/w/index.php?title=Data_science&action=history', '/wiki/Special:WhatLinksHere/Data_science', '/wiki/Special:RecentChangesLinked/Data_science', '/wiki/Wikipedia:File_Upload_Wizard', '/wiki/Special:SpecialPages', '/w/index.php?title=Data_science&oldid=1141056139', '/w/index.php?title=Data_science&action=info', '/w/index.php?title=Special:CiteThisPage&page=Data_science&id=1141056139&wpFormIdentifier=titleform', 'https://www.wikidata.org/wiki/Special:EntityPage/Q2374463', '/w/index.php?title=Special:DownloadAsPdf&page=Data_science&action=show-download-screen', '/w/index.php?title=Data_science&printable=yes', 'https://commons.wikimedia.org/wiki/Category:Data_science', 'https://en.wikiversity.org/wiki/Data_science', '/wiki/Information_science', '/wiki/File:PIA23792-1600x1200(1).jpg', '/wiki/File:PIA23792-1600x1200(1).jpg', '/wiki/Comet_NEOWISE', '/wiki/Astronomical_survey', '/wiki/Space_telescope', '/wiki/Wide-field_Infrared_Survey_Explorer', '/wiki/Interdisciplinary', '#cite_note-1', '/wiki/Statistics', '/wiki/Scientific_computing', '/wiki/Scientific_method', '/wiki/Algorithm', '/wiki/Knowledge', '/wiki/Unstructured_data', '#cite_note-2', '#cite_note-3', '#cite_note-4', '/wiki/Statistics', '/wiki/Data_analysis', '/wiki/Informatics', '/wiki/Scientific_method', '/wiki/Phenomena', '/wiki/Data', '#cite_note-5', '/wiki/Mathematics', '/wiki/Computer_science', '/wiki/Information_science', '/wiki/Domain_knowledge', '#cite_note-:2-6', '/wiki/Computer_science', '/wiki/Turing_Award', '/wiki/Jim_Gray_(computer_scientist)', '/wiki/Empirical_research', '/wiki/Basic_research', '/wiki/Computational_science', '/wiki/Information_technology', '/wiki/Information_explosion', '#cite_note-TansleyTolle2009-7', '#cite_note-BellHey2009-8', '#cite_note-9', '/w/index.php?title=Data_science&action=edit&section=1', '/wiki/Interdisciplinarity', '/wiki/Academic_discipline', '#cite_note-10', '/wiki/Big_data', '/wiki/Data_set', '/wiki/Problem_solving', '#cite_note-11', '/wiki/Analysis', '/wiki/Data_visualization', '/wiki/Information_visualization', '/wiki/Data_sonification', '/wiki/Data_integration', '/wiki/Graphic_design', '/wiki/Complex_systems', '/wiki/Communication', '/wiki/Business', '#cite_note-12', '#cite_note-13', '/wiki/Nathan_Yau', '/wiki/Ben_Fry', '/wiki/Human%E2%80%93computer_interaction', '/wiki/Exploration', '#cite_note-14', '#cite_note-15', '/wiki/American_Statistical_Association', '/wiki/Database', '/wiki/Machine_learning', '/wiki/Distributed_computing', '#cite_note-16', '/w/index.php?title=Data_science&action=edit&section=2', '/wiki/Nate_Silver', '#cite_note-17', '#cite_note-18', '/wiki/Vasant_Dhar', '#cite_note-19', '/wiki/Andrew_Gelman', '/wiki/Columbia_University', '#cite_note-20', '/wiki/David_Donoho', '#cite_note-:7-21', '/w/index.php?title=Data_science&action=edit&section=3', '/w/index.php?title=Data_science&action=edit&section=4', '/wiki/John_Tukey', '#cite_note-:7-21', '/wiki/C._F._Jeff_Wu', '#cite_note-22', '/wiki/Montpellier_2_University', '#cite_note-23', '#cite_note-Murtagh_2018_14-24', '/wiki/Peter_Naur', '#cite_note-:2-6', '#cite_note-:2-6', '/wiki/C._F._Jeff_Wu', '#cite_note-25', '#cite_note-Murtagh_2018_14-24', '/wiki/Data_mining', '#cite_note-:2-6', '#cite_note-:1-26', '/w/index.php?title=Data_science&action=edit&section=5', '/wiki/Thomas_H._Davenport', '/wiki/DJ_Patil', '#cite_note-27', '/wiki/New_York_Times', '#cite_note-28', '/wiki/Boston_Globe', '#cite_note-29', '#cite_note-30', '/wiki/William_S._Cleveland', '#cite_note-31', '#cite_note-:1-26', '/wiki/Committee_on_Data_for_Science_and_Technology', '#cite_note-:1-26', '/wiki/American_Statistical_Association', '#cite_note-32', '/wiki/DJ_Patil', '/wiki/Jeff_Hammerbacher', '#cite_note-33', '/wiki/National_Science_Board', '#cite_note-34', '/wiki/Buzzword', '#cite_note-35', '/wiki/Big_data', '#cite_note-:5-36', '#cite_note-:6-37', '/w/index.php?title=Data_science&action=edit&section=6', '/wiki/ODSC', '/wiki/Scientific_Data_(journal)', '/wiki/Women_in_Data', '/w/index.php?title=Data_science&action=edit&section=7', '#cite_ref-1', 'https://doi.org/10.1080%2F10618600.2017.1384734', '/wiki/Journal_of_Computational_and_Graphical_Statistics', '/wiki/Doi_(identifier)', 'https://doi.org/10.1080%2F10618600.2017.1384734', '/wiki/S2CID_(identifier)', 'https://api.semanticscholar.org/CorpusID:114558008', '#cite_ref-2', 'http://cacm.acm.org/magazines/2013/12/169933-data-science-and-prediction/fulltext', '/wiki/Doi_(identifier)', 'https://doi.org/10.1145%2F2500499', '/wiki/S2CID_(identifier)', 'https://api.semanticscholar.org/CorpusID:6107147', 'https://web.archive.org/web/20141109113411/http://cacm.acm.org/magazines/2013/12/169933-data-science-and-prediction/fulltext', '#cite_ref-3', 'https://dstf.acm.org/DSTF_Final_Report.pdf', '#cite_ref-4', 'https://cacm.acm.org/blogs/blog-cacm/267286-why-is-it-hard-to-define-data-science/fulltext', '#cite_ref-5', 'https://www.springer.com/book/9784431702085', '/wiki/Doi_(identifier)', 'https://doi.org/10.1007%2F978-4-431-65950-1_3', '/wiki/ISBN_(identifier)', '/wiki/Special:BookSources/9784431702085', '#cite_ref-:2_6-0', '#cite_ref-:2_6-1', '#cite_ref-:2_6-2', '#cite_ref-:2_6-3', 'https://doi.org/10.1145%2F3076253', '/wiki/Doi_(identifier)', 'https://doi.org/10.1145%2F3076253', '/wiki/ISSN_(identifier)', 'https://www.worldcat.org/issn/0360-0300', '/wiki/S2CID_(identifier)', 'https://api.semanticscholar.org/CorpusID:207595944', '#cite_ref-TansleyTolle2009_7-0', 'https://books.google.com/books?id=oGs_AQAAIAAJ', '/wiki/ISBN_(identifier)', '/wiki/Special:BookSources/978-0-9825442-0-4', 'https://web.archive.org/web/20170320193019/https://books.google.com/books?id=oGs_AQAAIAAJ', '#cite_ref-BellHey2009_8-0', '/wiki/Doi_(identifier)', 'https://doi.org/10.1126%2Fscience.1170411', '/wiki/ISSN_(identifier)', 'https://www.worldcat.org/issn/0036-8075', '/wiki/PMID_(identifier)', 'https://pubmed.ncbi.nlm.nih.gov/19265007', '/wiki/S2CID_(identifier)', 'https://api.semanticscholar.org/CorpusID:9743327', '#cite_ref-9', 'https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century/', '/wiki/Harvard_Business_Review', '/wiki/PMID_(identifier)', 'https://pubmed.ncbi.nlm.nih.gov/23074866', '#cite_ref-10', 'https://doi.org/10.3390%2Fmake1010015', '/wiki/Doi_(identifier)', 'https://doi.org/10.3390%2Fmake1010015', '#cite_ref-11', 'https://web.archive.org/web/20200810114002/http://www.datascienceassn.org/about-data-science', 'http://www.datascienceassn.org/about-data-science', '#cite_ref-12', 'https://www.oreilly.com/library/view/doing-data-science/9781449363871/ch01.html', '#cite_ref-13', 'https://medriscoll.com/post/4740157098/the-three-sexy-skills-of-data-geeks', '#cite_ref-14', 'https://flowingdata.com/2009/06/04/rise-of-the-data-scientist/', '#cite_ref-15', 'https://benfry.com/phd/dissertation/2.html', '#cite_ref-16', 'https://magazine.amstat.org/blog/2015/10/01/asa-statement-on-the-role-of-statistics-in-data-science/', '/wiki/American_Statistical_Association', 'https://web.archive.org/web/20190620184935/https://magazine.amstat.org/blog/2015/10/01/asa-statement-on-the-role-of-statistics-in-data-science/', '#cite_ref-17', 'https://www.statisticsviews.com/article/nate-silver-what-i-need-from-statisticians/', '#cite_ref-18', 'http://priceonomics.com/whats-the-difference-between-data-science-and/', '#cite_ref-19', 'http://archive.nyu.edu/handle/2451/31553', '/wiki/Doi_(identifier)', 'https://doi.org/10.1145%2F2500499', '/wiki/S2CID_(identifier)', 'https://api.semanticscholar.org/CorpusID:6107147', '#cite_ref-20', 'https://statmodeling.stat.columbia.edu/2013/11/14/statistics-least-important-part-data-science/', '#cite_ref-:7_21-0', '#cite_ref-:7_21-1', 'http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf', '#cite_ref-22', 'https://www2.isye.gatech.edu/~jeffwu/publications/fazhan.pdf', '/w/index.php?title=Application_of_Statistics_and_Management&action=edit&redlink=1', '#cite_ref-23', '/wiki/ISBN_(identifier)', '/wiki/Special:BookSources/0-12-241770-4', '/wiki/OCLC_(identifier)', 'https://www.worldcat.org/oclc/489990740', '#cite_ref-Murtagh_2018_14_24-0', '#cite_ref-Murtagh_2018_14_24-1', 'https://doi.org/10.3390%2Fbdcc2020014', '/wiki/Doi_(identifier)', 'https://doi.org/10.3390%2Fbdcc2020014', '#cite_ref-25', 'http://www2.isye.gatech.edu/~jeffwu/presentations/datascience.pdf', '#cite_ref-:1_26-0', '#cite_ref-:1_26-1', '#cite_ref-:1_26-2', 'https://www.forbes.com/sites/gilpress/2013/05/28/a-very-short-history-of-data-science/', '#cite_ref-27', 'https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century', '/wiki/Harvard_Business_Review', '#cite_ref-28', 'https://www.nytimes.com/2013/04/14/education/edlife/universities-offer-courses-in-a-hot-new-field-data-science.html', '/wiki/New_York_Times', '/wiki/New_York_City', '#cite_ref-29', 'https://www.bostonglobe.com/business/2015/11/11/behind-scenes-sexiest-job-century/Kc1cvXIu31DfHhVmyRQeIJ/story.html', '/wiki/Boston_Globe', '/wiki/Boston', '#cite_ref-30', 'https://hbr.org/2022/07/is-data-scientist-still-the-sexiest-job-of-the-21st-century', '/wiki/Harvard_Business_Review', '#cite_ref-31', 'https://www.stat.purdue.edu/~wsc/', '#cite_ref-32', 'https://magazine.amstat.org/blog/2016/06/01/datascience-2/', '/wiki/American_Statistical_Association', '#cite_ref-33', 'https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century', '/wiki/ISSN_(identifier)', 'https://www.worldcat.org/issn/0017-8012', '#cite_ref-34', 'https://www.nsf.gov/pubs/2005/nsb0540/', '#cite_ref-35', 'https://www.forbes.com/sites/gilpress/2013/08/19/data-science-whats-the-half-life-of-a-buzzword/', '/wiki/Forbes', '#cite_ref-:5_36-0', 'https://www.forbes.com/sites/peterpham/2015/08/28/the-impacts-of-big-data-that-you-may-not-have-heard-of/', '#cite_ref-:6_37-0', 'https://towardsdatascience.com/how-data-science-will-impact-future-of-businesses-7f11f5699c4d', '/wiki/Template:Data', '/wiki/Template_talk:Data', 'https://en.wikipedia.org/w/index.php?title=Template:Data&action=edit', '/wiki/Data_(computing)', '/wiki/Data_augmentation', '/wiki/Data_analysis', '/wiki/Data_archaeology', '/wiki/Big_data', '/wiki/Data_cleansing', '/wiki/Data_collection', '/wiki/Data_compression', '/wiki/Data_corruption', '/wiki/Data_curation', '/wiki/Data_degradation', '/wiki/Data_editing', '/wiki/Extract,_transform,_load', '/wiki/Extract,_load,_transform', '/wiki/Data_extraction', '/wiki/Data_transformation', '/wiki/Data_loading', '/wiki/Data_farming', '/wiki/Data_format_management', '/wiki/Data_fusion', '/wiki/Data_integration', '/wiki/Data_integrity', '/wiki/Data_library', '/wiki/Data_lineage', '/wiki/Data_loss', '/wiki/Data_management', '/wiki/Data_migration', '/wiki/Data_mining', '/wiki/Data_philanthropy', '/wiki/Data_pre-processing', '/wiki/Data_preservation', '/wiki/Information_privacy', '/wiki/Data_publishing', '/wiki/Data_recovery', '/wiki/Data_reduction', '/wiki/Data_retention', '/wiki/Data_quality', '/wiki/Data_scraping', '/wiki/Data_scrubbing', '/wiki/Data_security', '/wiki/Data_steward', '/wiki/Data_storage', '/wiki/Data_validation', '/wiki/Data_warehouse', '/wiki/Data_wrangling', 'https://en.wikipedia.org/w/index.php?title=Data_science&oldid=1141056139', '/wiki/Help:Category', '/wiki/Category:Information_science', '/wiki/Category:Computer_occupations', '/wiki/Category:Computational_fields_of_study', '/wiki/Category:Data_analysis', '/wiki/Category:Articles_with_short_description', '/wiki/Category:Short_description_is_different_from_Wikidata', '/wiki/Category:Use_dmy_dates_from_August_2021', '//en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License', '//creativecommons.org/licenses/by-sa/3.0/', '//foundation.wikimedia.org/wiki/Terms_of_Use', '//foundation.wikimedia.org/wiki/Privacy_policy', '//www.wikimediafoundation.org/', 'https://foundation.wikimedia.org/wiki/Privacy_policy', '/wiki/Wikipedia:About', '/wiki/Wikipedia:General_disclaimer', '//en.wikipedia.org/wiki/Wikipedia:Contact_us', '//en.m.wikipedia.org/w/index.php?title=Data_science&mobileaction=toggle_view_mobile', 'https://developer.wikimedia.org', 'https://stats.wikimedia.org/#/en.wikipedia.org', 'https://foundation.wikimedia.org/wiki/Cookie_statement', 'https://wikimediafoundation.org/', 'https://www.mediawiki.org/']\n"
     ]
    }
   ],
   "source": [
    "Url = 'https://en.wikipedia.org/wiki/Data_science'\n",
    "Urls = extract_urls(Url)\n",
    "print(Urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae8385",
   "metadata": {},
   "source": [
    "## Write a function to extract all the phone numbers from a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa854043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_phone(text):\n",
    "    \n",
    "    pattern = r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b'\n",
    "    \n",
    "    matches = re.findall(pattern,text)\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf720345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['123-234-5678']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hey my phone number is 123-234-5678\"\n",
    "print(extract_phone(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143df2dc",
   "metadata": {},
   "source": [
    "## Write a function CSV file with a large amount of data, how would you extract a specific subset of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ab1be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3654c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_csv_subset(ip_filename, op_filename, condition):\n",
    "    with open(ip_filename,'r') as input_file, open(op_filename, 'w', newline='') as output_file:\n",
    "        reader = csv.reader(input_file)\n",
    "        writer = csv.writer(output_file)\n",
    "        \n",
    "        writer.writerow(next(reader))\n",
    "        \n",
    "        for row in reader:\n",
    "            if condition(row):\n",
    "                writer.writerow(row)\n",
    "                \n",
    "def greater_than_10(row):\n",
    "    return int(row[0]) > 10 and int(row[1]) < 100 ## extarcts the data in first column > 10 and second column <100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b176c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_csv_subset('./attachments/telecom_churn.csv', './attachments/output.csv', greater_than_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc35089b",
   "metadata": {},
   "source": [
    "## Write a program to extract all the text from a PDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f239800e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecb3b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_text(file_path):\n",
    "    with fitz.open(file_path) as file:\n",
    "        \n",
    "        ##reader = PyPDF2.PdfReader(file)\n",
    "        \n",
    "        text = \"\"\n",
    "        for page in file:\n",
    "            text+=page.get_text()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c204479a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"N/A\\nN/A\\nManasa Shivarudra\\nmanasa.shivarudra@gmail.com\\n8067301117\\nhttps://www.linkedin.com/in/manasa-shivarudra/\\nSummary\\nSelf-taught Data Science and Machine Learning enthusiast seeking full time opportunities in Data Science and Machine Learning field. Dependable and \\nself-motivated software professional with 5 years experience working directly with the customer to build their outbound IVR applications in different \\nchannels. Worked as the Technical Lead for a 3 year implementation project which involved migration of 250 applications.\\nExperience\\nMachine Learning Engineer\\nOmdena AI, Philadelphia\\nJune 2021 - July 2022\\n|\\n|\\n• Collaborated on the end-to-end Machine Learning project to build a model to predict the Energy consumption in a building which involved data \\nprocessing, EDA, data visualization, feature engineering, model building and deployment on Azure ML Studio. \\n• Deployed the model in Azure machine learning studio by creating a real-time endpoints and inference pipelines. \\n• Designed and implemented various machine learning algorithms like Boosted Decision Trees, Random Forest, Support Vector Machine and Artificial \\nNeural Networks.\\nSoftware Engineer\\nNuance Communications Inc\\nMahwah, NJ, USA and Mississauga, Canada\\nOctober 2017 - October 2021\\n|\\n|\\n|\\n• Involved in customizing the IVR product based on complex client requirements.  \\n• Designed high volume Conversational AI apps using Nuance proprietary SDK and Nuance Voice Platform. \\n• Improved user experience for a conversational AI application for a top brand by 10% by developing a robust Conversational AI application on the voice \\nplatform. \\n• Mentored junior and offshore developers on a large-scale migration project in Scala framework to improve company's code quality metrics. \\n• Created and maintained high-level Technical Design Documents for more than 100 applications to meet project requirements and deadlines.  \\n• Delivered a global rollout of a new product to all production customers, meeting all deadlines and ensuring customer satisfaction.\\nTechnical Analyst\\nTrizetto Healthcare Solutions\\nArizona, USA\\nFebruary 2017 - August 2017\\n|\\n|\\n|\\n• Customized the Encounter Data Manager (EDM) to create EDI 837 files for medical claim submits by modifying SQL and C# code.\\nTechnical Analyst\\nOracle Financial Services Software Ltd\\nBangalore, India\\nOctober 2012 - December 2014\\n|\\n|\\n|\\n• Researched and resolved product enhancements for FLEXCUBE product by providing fixes to banks across geographies and increasing product stability \\nfor customers. \\n• Engaged in the product customization for consumer lending which included both the UI and Database changes (PL/SQL).\\nProjects\\nTweet Emotion Recognition with TensorFlow (Hugging Face Data)\\nMay 2022 - May 2022\\n|\\n• Built a Recurrent Neural Network for multi class classification of 6 emotions to train tweet emotion dataset to learn to recognize emotions in tweets. The \\nmodel performed with a training accuracy of 98.56% and validation accuracy of 88.35% with 7 epochs using TensorFlow.\\nTelecom Customers Churn Prediction\\nApril 2022 - April 2022\\n|\\n• Implemented various classification models like Logistic Regression, SVM, KNN, Random Forest Classifier to predict the churn rate of telecommunication \\ncustomers with an f1-score of 83% and an accuracy of 82%. Validated the models using the AUROC and ROC curves.\\nBank Personal Loan Acceptance Prediction\\nApril 2022 - April 2022\\n|\\n• Built a simple multilayer neural network model for predicting the probability of customers accepting the Personal Loan. Trained the model with ANN \\nwith a training accuracy of 99.19% and a test accuracy of 98%.\\nEducation\\nMasters in Computer Science\\nTexas Tech University\\n3.6\\nTexas, USA 2016\\n|\\n|\\n|\\n|\\n|\\nBachelors of Engineering in Computer Science\\nVisvesvaraya Technological University\\n3.8\\nKarnataka, India 2012\\n|\\n|\\n|\\n|\\n|\\nCertifications\\nMicrosoft : Azure Fundamentals, Azure Data Fundamentals, Azure AI Fundamentals, Azure AI Engineer Associate\\n2021\\n|\\nSkills\\nPython, Scikit- Learn, Pandas, Numpy, Seaborn, TensorFlow, pytorch, pyspark, BERT, Scala, Azure, Linear Regression, Logistic Regression, NLP, SVM, K-\\nmeans, Decision Trees, Random Forest, ANN, EDA, Data Visualization, Statistics, SQLite, SQL Server, Mongo DB/Atlas, Kubernetes, Apache Spark, Git\\n\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_pdf_text('./ManasaShivarudra_CV.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c5cb4fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'camelot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3952/2157033693.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Second way of writing the above using camelot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcamelot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'camelot'"
     ]
    }
   ],
   "source": [
    "## Second way of writing the above using camelot\n",
    "\n",
    "import camelot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80febc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    tables = camelot.read_pdf(file_path, pages='all', flavor='stream')\n",
    "    text=\"\"\n",
    "    for table in tables:\n",
    "        text+= table.df.to_string()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e938e7b",
   "metadata": {},
   "source": [
    "## Given a string of HTML code, write a optimized python function to extract all the links from the HTML code.\n",
    "\n",
    "time complexity of O(n), where n is the total number of characters in the HTML code. \n",
    "\n",
    "this program has a space complexity of O(k), where k is the number of links in the HTML code. This is because we store the links in a list, which takes up space proportional to the number of links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8a644cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_links(filename):\n",
    "    \n",
    "    html_file = open(filename,'r', encoding=\"utf8\")\n",
    "    \n",
    "    soup = BeautifulSoup(html_file, 'html.parser')\n",
    "    links=[]\n",
    "    \n",
    "    for link in soup.find_all('a'):\n",
    "        if 'href' in link.attrs:\n",
    "            links.append(link.attrs['href'])\n",
    "    \n",
    "    #for link in soup.find_all('a'):\n",
    "        #href= link.get('href')\n",
    "       # if href is not None:\n",
    "         #if 'href' in link.attrs:\n",
    "            #links.append(link.attrs['href'])\n",
    "\n",
    "            #links.append(href)\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d4b17749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/wiki/Data_science#bodyContent',\n",
       " 'https://en.wikipedia.org/wiki/Main_Page',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:Contents',\n",
       " 'https://en.wikipedia.org/wiki/Portal:Current_events',\n",
       " 'https://en.wikipedia.org/wiki/Special:Random',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:About',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:Contact_us',\n",
       " 'https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en',\n",
       " 'https://en.wikipedia.org/wiki/Help:Contents',\n",
       " 'https://en.wikipedia.org/wiki/Help:Introduction',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:Community_portal',\n",
       " 'https://en.wikipedia.org/wiki/Special:RecentChanges',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:File_upload_wizard',\n",
       " 'https://en.wikipedia.org/wiki/Main_Page',\n",
       " 'https://en.wikipedia.org/wiki/Special:Search',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Data+science',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Data+science',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Data+science',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Data+science',\n",
       " 'https://en.wikipedia.org/wiki/Help:Introduction',\n",
       " 'https://en.wikipedia.org/wiki/Special:MyContributions',\n",
       " 'https://en.wikipedia.org/wiki/Special:MyTalk',\n",
       " 'https://commons.wikimedia.org/wiki/Special:MyLanguage/Commons:Wiki_Loves_Folklore_2023',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#Foundations',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#Relationship_to_statistics',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#Etymology',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#Early_usage',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#Modern_usage',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#See_also',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#References',\n",
       " 'https://ar.wikipedia.org/wiki/%D8%B9%D9%84%D9%85_%D8%A7%D9%84%D8%A8%D9%8A%D8%A7%D9%86%D8%A7%D8%AA',\n",
       " 'https://az.wikipedia.org/wiki/Veril%C9%99nl%C9%99r_elmi_(Data_Science)',\n",
       " 'https://bn.wikipedia.org/wiki/%E0%A6%89%E0%A6%AA%E0%A6%BE%E0%A6%A4%E0%A7%8D%E0%A6%A4_%E0%A6%AC%E0%A6%BF%E0%A6%9C%E0%A7%8D%E0%A6%9E%E0%A6%BE%E0%A6%A8',\n",
       " 'https://bg.wikipedia.org/wiki/%D0%9D%D0%B0%D1%83%D0%BA%D0%B0_%D0%B7%D0%B0_%D0%B4%D0%B0%D0%BD%D0%BD%D0%B8%D1%82%D0%B5',\n",
       " 'https://ca.wikipedia.org/wiki/Ci%C3%A8ncia_de_les_dades',\n",
       " 'https://cs.wikipedia.org/wiki/Data_science',\n",
       " 'https://de.wikipedia.org/wiki/Data_Science',\n",
       " 'https://et.wikipedia.org/wiki/Andmeteadus',\n",
       " 'https://el.wikipedia.org/wiki/%CE%95%CF%80%CE%B9%CF%83%CF%84%CE%AE%CE%BC%CE%B7_%CE%B4%CE%B5%CE%B4%CE%BF%CE%BC%CE%AD%CE%BD%CF%89%CE%BD',\n",
       " 'https://es.wikipedia.org/wiki/Ciencia_de_datos',\n",
       " 'https://eo.wikipedia.org/wiki/Datuma_scienco',\n",
       " 'https://eu.wikipedia.org/wiki/Datu_zientzia',\n",
       " 'https://fa.wikipedia.org/wiki/%D8%B9%D9%84%D9%85_%D8%AF%D8%A7%D8%AF%D9%87%E2%80%8C%D9%87%D8%A7',\n",
       " 'https://fr.wikipedia.org/wiki/Science_des_donn%C3%A9es',\n",
       " 'https://ko.wikipedia.org/wiki/%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%82%AC%EC%9D%B4%EC%96%B8%EC%8A%A4',\n",
       " 'https://hy.wikipedia.org/wiki/%D5%8F%D5%BE%D5%B5%D5%A1%D5%AC%D5%B6%D5%A5%D6%80%D5%AB_%D5%A3%D5%AB%D5%BF%D5%B8%D6%82%D5%A9%D5%B5%D5%B8%D6%82%D5%B6',\n",
       " 'https://hi.wikipedia.org/wiki/%E0%A4%86%E0%A4%81%E0%A4%95%E0%A4%A1%E0%A4%BC%E0%A4%BE_%E0%A4%B5%E0%A4%BF%E0%A4%9C%E0%A5%8D%E0%A4%9E%E0%A4%BE%E0%A4%A8',\n",
       " 'https://id.wikipedia.org/wiki/Ilmu_data',\n",
       " 'https://it.wikipedia.org/wiki/Scienza_dei_dati',\n",
       " 'https://he.wikipedia.org/wiki/%D7%9E%D7%93%D7%A2_%D7%94%D7%A0%D7%AA%D7%95%D7%A0%D7%99%D7%9D',\n",
       " 'https://kn.wikipedia.org/wiki/%E0%B2%A6%E0%B2%A4%E0%B3%8D%E0%B2%A4%E0%B2%BE%E0%B2%82%E0%B2%B6_%E0%B2%B5%E0%B2%BF%E0%B2%9C%E0%B3%8D%E0%B2%9E%E0%B2%BE%E0%B2%A8',\n",
       " 'https://kk.wikipedia.org/wiki/%D0%94%D0%B5%D1%80%D0%B5%D0%BA%D1%82%D0%B5%D1%80_%D1%82%D1%83%D1%80%D0%B0%D0%BB%D1%8B_%D2%93%D1%8B%D0%BB%D1%8B%D0%BC',\n",
       " 'https://lv.wikipedia.org/wiki/Datu_m%C4%81c%C4%ABba',\n",
       " 'https://mk.wikipedia.org/wiki/%D0%9D%D0%B0%D1%83%D0%BA%D0%B0_%D0%B7%D0%B0_%D0%BF%D0%BE%D0%B4%D0%B0%D1%82%D0%BE%D1%86%D0%B8%D1%82%D0%B5',\n",
       " 'https://ms.wikipedia.org/wiki/Sains_data',\n",
       " 'https://my.wikipedia.org/wiki/%E1%80%A1%E1%80%81%E1%80%BB%E1%80%80%E1%80%BA%E1%80%A1%E1%80%9C%E1%80%80%E1%80%BA%E1%80%9E%E1%80%AD%E1%80%95%E1%80%B9%E1%80%95%E1%80%B6%E1%80%95%E1%80%8A%E1%80%AC',\n",
       " 'https://nl.wikipedia.org/wiki/Datawetenschap',\n",
       " 'https://ja.wikipedia.org/wiki/%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9',\n",
       " 'https://no.wikipedia.org/wiki/Datavitenskap',\n",
       " 'https://uz.wikipedia.org/wiki/Ma%27lumotlar_ombori',\n",
       " 'https://pl.wikipedia.org/wiki/Danologia',\n",
       " 'https://pt.wikipedia.org/wiki/Ci%C3%AAncia_de_dados',\n",
       " 'https://qu.wikipedia.org/wiki/Willakuy_hamut%27ay',\n",
       " 'https://ru.wikipedia.org/wiki/%D0%9D%D0%B0%D1%83%D0%BA%D0%B0_%D0%BE_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85',\n",
       " 'https://simple.wikipedia.org/wiki/Data_science',\n",
       " 'https://fi.wikipedia.org/wiki/Datatiede',\n",
       " 'https://ta.wikipedia.org/wiki/%E0%AE%A4%E0%AE%B0%E0%AE%B5%E0%AF%81_%E0%AE%85%E0%AE%B1%E0%AE%BF%E0%AE%B5%E0%AE%BF%E0%AE%AF%E0%AE%B2%E0%AF%8D',\n",
       " 'https://th.wikipedia.org/wiki/%E0%B8%A7%E0%B8%B4%E0%B8%97%E0%B8%A2%E0%B8%B2%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B8%82%E0%B9%89%E0%B8%AD%E0%B8%A1%E0%B8%B9%E0%B8%A5',\n",
       " 'https://tr.wikipedia.org/wiki/Veri_bilimi',\n",
       " 'https://uk.wikipedia.org/wiki/%D0%9D%D0%B0%D1%83%D0%BA%D0%B0_%D0%BF%D1%80%D0%BE_%D0%B4%D0%B0%D0%BD%D1%96',\n",
       " 'https://ur.wikipedia.org/wiki/%DA%88%DB%8C%D9%B9%D8%A7_%D8%B3%D8%A7%D8%A6%D9%86%D8%B3',\n",
       " 'https://vi.wikipedia.org/wiki/Khoa_h%E1%BB%8Dc_d%E1%BB%AF_li%E1%BB%87u',\n",
       " 'https://zh-yue.wikipedia.org/wiki/%E6%95%B8%E6%93%9A%E7%A7%91%E5%AD%B8',\n",
       " 'https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6',\n",
       " 'https://en.wikipedia.org/wiki/Data_science',\n",
       " 'https://en.wikipedia.org/wiki/Talk:Data_science',\n",
       " 'https://en.wikipedia.org/wiki/Data_science',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Data_science&action=edit',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Data_science&action=history',\n",
       " 'https://en.wikipedia.org/wiki/Data_science',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Data_science&action=edit',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Data_science&action=history',\n",
       " 'https://en.wikipedia.org/wiki/Special:WhatLinksHere/Data_science',\n",
       " 'https://en.wikipedia.org/wiki/Special:RecentChangesLinked/Data_science',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard',\n",
       " 'https://en.wikipedia.org/wiki/Special:SpecialPages',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Data_science&oldid=1141056139',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Data_science&action=info',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Data_science&id=1141056139&wpFormIdentifier=titleform',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q2374463',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q2374463#sitelinks-wikipedia',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&page=Data_science&action=show-download-screen',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Data_science&printable=yes',\n",
       " 'https://commons.wikimedia.org/wiki/Category:Data_science',\n",
       " 'https://en.wikiversity.org/wiki/Data_science',\n",
       " 'https://en.wikipedia.org/wiki/Information_science',\n",
       " 'https://en.wikipedia.org/wiki/File:PIA23792-1600x1200(1).jpg',\n",
       " 'https://en.wikipedia.org/wiki/File:PIA23792-1600x1200(1).jpg',\n",
       " 'https://en.wikipedia.org/wiki/Comet_NEOWISE',\n",
       " 'https://en.wikipedia.org/wiki/Astronomical_survey',\n",
       " 'https://en.wikipedia.org/wiki/Space_telescope',\n",
       " 'https://en.wikipedia.org/wiki/Wide-field_Infrared_Survey_Explorer',\n",
       " 'https://en.wikipedia.org/wiki/Interdisciplinary',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-1',\n",
       " 'https://en.wikipedia.org/wiki/Statistics',\n",
       " 'https://en.wikipedia.org/wiki/Scientific_computing',\n",
       " 'https://en.wikipedia.org/wiki/Scientific_method',\n",
       " 'https://en.wikipedia.org/wiki/Algorithm',\n",
       " 'https://en.wikipedia.org/wiki/Knowledge',\n",
       " 'https://en.wikipedia.org/wiki/Unstructured_data',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-2',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-3',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-4',\n",
       " 'https://en.wikipedia.org/wiki/Statistics',\n",
       " 'https://en.wikipedia.org/wiki/Data_analysis',\n",
       " 'https://en.wikipedia.org/wiki/Informatics',\n",
       " 'https://en.wikipedia.org/wiki/Scientific_method',\n",
       " 'https://en.wikipedia.org/wiki/Phenomena',\n",
       " 'https://en.wikipedia.org/wiki/Data',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-5',\n",
       " 'https://en.wikipedia.org/wiki/Mathematics',\n",
       " 'https://en.wikipedia.org/wiki/Computer_science',\n",
       " 'https://en.wikipedia.org/wiki/Information_science',\n",
       " 'https://en.wikipedia.org/wiki/Domain_knowledge',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-:2-6',\n",
       " 'https://en.wikipedia.org/wiki/Computer_science',\n",
       " 'https://en.wikipedia.org/wiki/Turing_Award',\n",
       " 'https://en.wikipedia.org/wiki/Jim_Gray_(computer_scientist)',\n",
       " 'https://en.wikipedia.org/wiki/Empirical_research',\n",
       " 'https://en.wikipedia.org/wiki/Basic_research',\n",
       " 'https://en.wikipedia.org/wiki/Computational_science',\n",
       " 'https://en.wikipedia.org/wiki/Information_technology',\n",
       " 'https://en.wikipedia.org/wiki/Information_explosion',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-TansleyTolle2009-7',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-BellHey2009-8',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-9',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Data_science&action=edit&section=1',\n",
       " 'https://en.wikipedia.org/wiki/Interdisciplinarity',\n",
       " 'https://en.wikipedia.org/wiki/Academic_discipline',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-10',\n",
       " 'https://en.wikipedia.org/wiki/Big_data',\n",
       " 'https://en.wikipedia.org/wiki/Data_set',\n",
       " 'https://en.wikipedia.org/wiki/Problem_solving',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-11',\n",
       " 'https://en.wikipedia.org/wiki/Analysis',\n",
       " 'https://en.wikipedia.org/wiki/Data_visualization',\n",
       " 'https://en.wikipedia.org/wiki/Information_visualization',\n",
       " 'https://en.wikipedia.org/wiki/Data_sonification',\n",
       " 'https://en.wikipedia.org/wiki/Data_integration',\n",
       " 'https://en.wikipedia.org/wiki/Graphic_design',\n",
       " 'https://en.wikipedia.org/wiki/Complex_systems',\n",
       " 'https://en.wikipedia.org/wiki/Communication',\n",
       " 'https://en.wikipedia.org/wiki/Business',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-12',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-13',\n",
       " 'https://en.wikipedia.org/wiki/Nathan_Yau',\n",
       " 'https://en.wikipedia.org/wiki/Ben_Fry',\n",
       " 'https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction',\n",
       " 'https://en.wikipedia.org/wiki/Exploration',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-14',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-15',\n",
       " 'https://en.wikipedia.org/wiki/American_Statistical_Association',\n",
       " 'https://en.wikipedia.org/wiki/Database',\n",
       " 'https://en.wikipedia.org/wiki/Machine_learning',\n",
       " 'https://en.wikipedia.org/wiki/Distributed_computing',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-16',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Data_science&action=edit&section=2',\n",
       " 'https://en.wikipedia.org/wiki/Nate_Silver',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-17',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-18',\n",
       " 'https://en.wikipedia.org/wiki/Vasant_Dhar',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-19',\n",
       " 'https://en.wikipedia.org/wiki/Andrew_Gelman',\n",
       " 'https://en.wikipedia.org/wiki/Columbia_University',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-20',\n",
       " 'https://en.wikipedia.org/wiki/David_Donoho',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-:7-21',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Data_science&action=edit&section=3',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Data_science&action=edit&section=4',\n",
       " 'https://en.wikipedia.org/wiki/John_Tukey',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-:7-21',\n",
       " 'https://en.wikipedia.org/wiki/C._F._Jeff_Wu',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-22',\n",
       " 'https://en.wikipedia.org/wiki/Montpellier_2_University',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-23',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-Murtagh_2018_14-24',\n",
       " 'https://en.wikipedia.org/wiki/Peter_Naur',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-:2-6',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-:2-6',\n",
       " 'https://en.wikipedia.org/wiki/C._F._Jeff_Wu',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-25',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-Murtagh_2018_14-24',\n",
       " 'https://en.wikipedia.org/wiki/Data_mining',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-:2-6',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-:1-26',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Data_science&action=edit&section=5',\n",
       " 'https://en.wikipedia.org/wiki/Thomas_H._Davenport',\n",
       " 'https://en.wikipedia.org/wiki/DJ_Patil',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-27',\n",
       " 'https://en.wikipedia.org/wiki/New_York_Times',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-28',\n",
       " 'https://en.wikipedia.org/wiki/Boston_Globe',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-29',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-30',\n",
       " 'https://en.wikipedia.org/wiki/William_S._Cleveland',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-31',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-:1-26',\n",
       " 'https://en.wikipedia.org/wiki/Committee_on_Data_for_Science_and_Technology',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-:1-26',\n",
       " 'https://en.wikipedia.org/wiki/American_Statistical_Association',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-32',\n",
       " 'https://en.wikipedia.org/wiki/DJ_Patil',\n",
       " 'https://en.wikipedia.org/wiki/Jeff_Hammerbacher',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-33',\n",
       " 'https://en.wikipedia.org/wiki/National_Science_Board',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-34',\n",
       " 'https://en.wikipedia.org/wiki/Buzzword',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-35',\n",
       " 'https://en.wikipedia.org/wiki/Big_data',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-:5-36',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_note-:6-37',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Data_science&action=edit&section=6',\n",
       " 'https://en.wikipedia.org/wiki/ODSC',\n",
       " 'https://en.wikipedia.org/wiki/Scientific_Data_(journal)',\n",
       " 'https://en.wikipedia.org/wiki/Women_in_Data',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Data_science&action=edit&section=7',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-1',\n",
       " 'https://doi.org/10.1080%2F10618600.2017.1384734',\n",
       " 'https://en.wikipedia.org/wiki/Journal_of_Computational_and_Graphical_Statistics',\n",
       " 'https://en.wikipedia.org/wiki/Doi_(identifier)',\n",
       " 'https://doi.org/10.1080%2F10618600.2017.1384734',\n",
       " 'https://en.wikipedia.org/wiki/S2CID_(identifier)',\n",
       " 'https://api.semanticscholar.org/CorpusID:114558008',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-2',\n",
       " 'http://cacm.acm.org/magazines/2013/12/169933-data-science-and-prediction/fulltext',\n",
       " 'https://en.wikipedia.org/wiki/Doi_(identifier)',\n",
       " 'https://doi.org/10.1145%2F2500499',\n",
       " 'https://en.wikipedia.org/wiki/S2CID_(identifier)',\n",
       " 'https://api.semanticscholar.org/CorpusID:6107147',\n",
       " 'https://web.archive.org/web/20141109113411/http://cacm.acm.org/magazines/2013/12/169933-data-science-and-prediction/fulltext',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-3',\n",
       " 'https://dstf.acm.org/DSTF_Final_Report.pdf',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-4',\n",
       " 'https://cacm.acm.org/blogs/blog-cacm/267286-why-is-it-hard-to-define-data-science/fulltext',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-5',\n",
       " 'https://www.springer.com/book/9784431702085',\n",
       " 'https://en.wikipedia.org/wiki/Doi_(identifier)',\n",
       " 'https://doi.org/10.1007%2F978-4-431-65950-1_3',\n",
       " 'https://en.wikipedia.org/wiki/ISBN_(identifier)',\n",
       " 'https://en.wikipedia.org/wiki/Special:BookSources/9784431702085',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-:2_6-0',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-:2_6-1',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-:2_6-2',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-:2_6-3',\n",
       " 'https://doi.org/10.1145%2F3076253',\n",
       " 'https://en.wikipedia.org/wiki/Doi_(identifier)',\n",
       " 'https://doi.org/10.1145%2F3076253',\n",
       " 'https://en.wikipedia.org/wiki/ISSN_(identifier)',\n",
       " 'https://www.worldcat.org/issn/0360-0300',\n",
       " 'https://en.wikipedia.org/wiki/S2CID_(identifier)',\n",
       " 'https://api.semanticscholar.org/CorpusID:207595944',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-TansleyTolle2009_7-0',\n",
       " 'https://books.google.com/books?id=oGs_AQAAIAAJ',\n",
       " 'https://en.wikipedia.org/wiki/ISBN_(identifier)',\n",
       " 'https://en.wikipedia.org/wiki/Special:BookSources/978-0-9825442-0-4',\n",
       " 'https://web.archive.org/web/20170320193019/https://books.google.com/books?id=oGs_AQAAIAAJ',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-BellHey2009_8-0',\n",
       " 'https://en.wikipedia.org/wiki/Doi_(identifier)',\n",
       " 'https://doi.org/10.1126%2Fscience.1170411',\n",
       " 'https://en.wikipedia.org/wiki/ISSN_(identifier)',\n",
       " 'https://www.worldcat.org/issn/0036-8075',\n",
       " 'https://en.wikipedia.org/wiki/PMID_(identifier)',\n",
       " 'https://pubmed.ncbi.nlm.nih.gov/19265007',\n",
       " 'https://en.wikipedia.org/wiki/S2CID_(identifier)',\n",
       " 'https://api.semanticscholar.org/CorpusID:9743327',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-9',\n",
       " 'https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century/',\n",
       " 'https://en.wikipedia.org/wiki/Harvard_Business_Review',\n",
       " 'https://en.wikipedia.org/wiki/PMID_(identifier)',\n",
       " 'https://pubmed.ncbi.nlm.nih.gov/23074866',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-10',\n",
       " 'https://doi.org/10.3390%2Fmake1010015',\n",
       " 'https://en.wikipedia.org/wiki/Doi_(identifier)',\n",
       " 'https://doi.org/10.3390%2Fmake1010015',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-11',\n",
       " 'https://web.archive.org/web/20200810114002/http://www.datascienceassn.org/about-data-science',\n",
       " 'http://www.datascienceassn.org/about-data-science',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-12',\n",
       " 'https://www.oreilly.com/library/view/doing-data-science/9781449363871/ch01.html',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-13',\n",
       " 'https://medriscoll.com/post/4740157098/the-three-sexy-skills-of-data-geeks',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-14',\n",
       " 'https://flowingdata.com/2009/06/04/rise-of-the-data-scientist/',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-15',\n",
       " 'https://benfry.com/phd/dissertation/2.html',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-16',\n",
       " 'https://magazine.amstat.org/blog/2015/10/01/asa-statement-on-the-role-of-statistics-in-data-science/',\n",
       " 'https://en.wikipedia.org/wiki/American_Statistical_Association',\n",
       " 'https://web.archive.org/web/20190620184935/https://magazine.amstat.org/blog/2015/10/01/asa-statement-on-the-role-of-statistics-in-data-science/',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-17',\n",
       " 'https://www.statisticsviews.com/article/nate-silver-what-i-need-from-statisticians/',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-18',\n",
       " 'http://priceonomics.com/whats-the-difference-between-data-science-and/',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-19',\n",
       " 'http://archive.nyu.edu/handle/2451/31553',\n",
       " 'https://en.wikipedia.org/wiki/Doi_(identifier)',\n",
       " 'https://doi.org/10.1145%2F2500499',\n",
       " 'https://en.wikipedia.org/wiki/S2CID_(identifier)',\n",
       " 'https://api.semanticscholar.org/CorpusID:6107147',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-20',\n",
       " 'https://statmodeling.stat.columbia.edu/2013/11/14/statistics-least-important-part-data-science/',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-:7_21-0',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-:7_21-1',\n",
       " 'http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-22',\n",
       " 'https://www2.isye.gatech.edu/~jeffwu/publications/fazhan.pdf',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Application_of_Statistics_and_Management&action=edit&redlink=1',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-23',\n",
       " 'https://en.wikipedia.org/wiki/ISBN_(identifier)',\n",
       " 'https://en.wikipedia.org/wiki/Special:BookSources/0-12-241770-4',\n",
       " 'https://en.wikipedia.org/wiki/OCLC_(identifier)',\n",
       " 'https://www.worldcat.org/oclc/489990740',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-Murtagh_2018_14_24-0',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-Murtagh_2018_14_24-1',\n",
       " 'https://doi.org/10.3390%2Fbdcc2020014',\n",
       " 'https://en.wikipedia.org/wiki/Doi_(identifier)',\n",
       " 'https://doi.org/10.3390%2Fbdcc2020014',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-25',\n",
       " 'http://www2.isye.gatech.edu/~jeffwu/presentations/datascience.pdf',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-:1_26-0',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-:1_26-1',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-:1_26-2',\n",
       " 'https://www.forbes.com/sites/gilpress/2013/05/28/a-very-short-history-of-data-science/',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-27',\n",
       " 'https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century',\n",
       " 'https://en.wikipedia.org/wiki/Harvard_Business_Review',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-28',\n",
       " 'https://www.nytimes.com/2013/04/14/education/edlife/universities-offer-courses-in-a-hot-new-field-data-science.html',\n",
       " 'https://en.wikipedia.org/wiki/New_York_Times',\n",
       " 'https://en.wikipedia.org/wiki/New_York_City',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-29',\n",
       " 'https://www.bostonglobe.com/business/2015/11/11/behind-scenes-sexiest-job-century/Kc1cvXIu31DfHhVmyRQeIJ/story.html',\n",
       " 'https://en.wikipedia.org/wiki/Boston_Globe',\n",
       " 'https://en.wikipedia.org/wiki/Boston',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-30',\n",
       " 'https://hbr.org/2022/07/is-data-scientist-still-the-sexiest-job-of-the-21st-century',\n",
       " 'https://en.wikipedia.org/wiki/Harvard_Business_Review',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-31',\n",
       " 'https://www.stat.purdue.edu/~wsc/',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-32',\n",
       " 'https://magazine.amstat.org/blog/2016/06/01/datascience-2/',\n",
       " 'https://en.wikipedia.org/wiki/American_Statistical_Association',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-33',\n",
       " 'https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century',\n",
       " 'https://en.wikipedia.org/wiki/ISSN_(identifier)',\n",
       " 'https://www.worldcat.org/issn/0017-8012',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-34',\n",
       " 'https://www.nsf.gov/pubs/2005/nsb0540/',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-35',\n",
       " 'https://www.forbes.com/sites/gilpress/2013/08/19/data-science-whats-the-half-life-of-a-buzzword/',\n",
       " 'https://en.wikipedia.org/wiki/Forbes',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-:5_36-0',\n",
       " 'https://www.forbes.com/sites/peterpham/2015/08/28/the-impacts-of-big-data-that-you-may-not-have-heard-of/',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#cite_ref-:6_37-0',\n",
       " 'https://towardsdatascience.com/how-data-science-will-impact-future-of-businesses-7f11f5699c4d',\n",
       " 'https://en.wikipedia.org/wiki/Template:Data',\n",
       " 'https://en.wikipedia.org/wiki/Template_talk:Data',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Template:Data&action=edit',\n",
       " 'https://en.wikipedia.org/wiki/Data_(computing)',\n",
       " 'https://en.wikipedia.org/wiki/Data_augmentation',\n",
       " 'https://en.wikipedia.org/wiki/Data_analysis',\n",
       " 'https://en.wikipedia.org/wiki/Data_archaeology',\n",
       " 'https://en.wikipedia.org/wiki/Big_data',\n",
       " 'https://en.wikipedia.org/wiki/Data_cleansing',\n",
       " 'https://en.wikipedia.org/wiki/Data_collection',\n",
       " 'https://en.wikipedia.org/wiki/Data_compression',\n",
       " 'https://en.wikipedia.org/wiki/Data_corruption',\n",
       " 'https://en.wikipedia.org/wiki/Data_curation',\n",
       " 'https://en.wikipedia.org/wiki/Data_degradation',\n",
       " 'https://en.wikipedia.org/wiki/Data_editing',\n",
       " 'https://en.wikipedia.org/wiki/Extract,_transform,_load',\n",
       " 'https://en.wikipedia.org/wiki/Extract,_load,_transform',\n",
       " 'https://en.wikipedia.org/wiki/Data_extraction',\n",
       " 'https://en.wikipedia.org/wiki/Data_transformation',\n",
       " 'https://en.wikipedia.org/wiki/Data_loading',\n",
       " 'https://en.wikipedia.org/wiki/Data_farming',\n",
       " 'https://en.wikipedia.org/wiki/Data_format_management',\n",
       " 'https://en.wikipedia.org/wiki/Data_fusion',\n",
       " 'https://en.wikipedia.org/wiki/Data_integration',\n",
       " 'https://en.wikipedia.org/wiki/Data_integrity',\n",
       " 'https://en.wikipedia.org/wiki/Data_library',\n",
       " 'https://en.wikipedia.org/wiki/Data_lineage',\n",
       " 'https://en.wikipedia.org/wiki/Data_loss',\n",
       " 'https://en.wikipedia.org/wiki/Data_management',\n",
       " 'https://en.wikipedia.org/wiki/Data_migration',\n",
       " 'https://en.wikipedia.org/wiki/Data_mining',\n",
       " 'https://en.wikipedia.org/wiki/Data_philanthropy',\n",
       " 'https://en.wikipedia.org/wiki/Data_pre-processing',\n",
       " 'https://en.wikipedia.org/wiki/Data_preservation',\n",
       " 'https://en.wikipedia.org/wiki/Information_privacy',\n",
       " 'https://en.wikipedia.org/wiki/Data_publishing',\n",
       " 'https://en.wikipedia.org/wiki/Data_recovery',\n",
       " 'https://en.wikipedia.org/wiki/Data_reduction',\n",
       " 'https://en.wikipedia.org/wiki/Data_retention',\n",
       " 'https://en.wikipedia.org/wiki/Data_quality',\n",
       " 'https://en.wikipedia.org/wiki/Data_scraping',\n",
       " 'https://en.wikipedia.org/wiki/Data_scrubbing',\n",
       " 'https://en.wikipedia.org/wiki/Data_security',\n",
       " 'https://en.wikipedia.org/wiki/Data_steward',\n",
       " 'https://en.wikipedia.org/wiki/Data_storage',\n",
       " 'https://en.wikipedia.org/wiki/Data_validation',\n",
       " 'https://en.wikipedia.org/wiki/Data_warehouse',\n",
       " 'https://en.wikipedia.org/wiki/Data_wrangling',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Data_science&oldid=1141056139',\n",
       " 'https://en.wikipedia.org/wiki/Help:Category',\n",
       " 'https://en.wikipedia.org/wiki/Category:Information_science',\n",
       " 'https://en.wikipedia.org/wiki/Category:Computer_occupations',\n",
       " 'https://en.wikipedia.org/wiki/Category:Computational_fields_of_study',\n",
       " 'https://en.wikipedia.org/wiki/Category:Data_analysis',\n",
       " 'https://en.wikipedia.org/wiki/Category:Articles_with_short_description',\n",
       " 'https://en.wikipedia.org/wiki/Category:Short_description_is_different_from_Wikidata',\n",
       " 'https://en.wikipedia.org/wiki/Category:Use_dmy_dates_from_August_2021',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License',\n",
       " 'https://creativecommons.org/licenses/by-sa/3.0/',\n",
       " 'https://foundation.wikimedia.org/wiki/Terms_of_Use',\n",
       " 'https://foundation.wikimedia.org/wiki/Privacy_policy',\n",
       " 'https://www.wikimediafoundation.org/',\n",
       " 'https://foundation.wikimedia.org/wiki/Privacy_policy',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:About',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:General_disclaimer',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:Contact_us',\n",
       " 'https://en.m.wikipedia.org/w/index.php?title=Data_science&mobileaction=toggle_view_mobile',\n",
       " 'https://developer.wikimedia.org/',\n",
       " 'https://stats.wikimedia.org/#/en.wikipedia.org',\n",
       " 'https://foundation.wikimedia.org/wiki/Cookie_statement',\n",
       " 'https://en.wikipedia.org/wiki/Data_science#',\n",
       " 'https://wikimediafoundation.org/',\n",
       " 'https://www.mediawiki.org/',\n",
       " 'https://en.wikipedia.org/wiki/Data_science?action=edit']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_links('./Data science - Wikipedia.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537dfaa6",
   "metadata": {},
   "source": [
    "## Write a function to extract all the hashtags from a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "08c94dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hashtags(text):\n",
    "    pattern = r'#\\w+'\n",
    "    return re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "472f5f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#doglover', '#queen']\n"
     ]
    }
   ],
   "source": [
    "text = \"I am a queen. #doglover #queen\"\n",
    "print(extract_hashtags(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b62b0",
   "metadata": {},
   "source": [
    "## Given a string of JSON data, write an optimized program to extract specific fields from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0e6b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4256ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fields(json_string, field_names):\n",
    "    data = json.loads(json_string)\n",
    "    result = []\n",
    "    for item in data:\n",
    "        extracted_fields = {}\n",
    "        for field_name in field_names:\n",
    "            if field_name in item:\n",
    "                extracted_fields[field_name] = item[field_name]\n",
    "        result.append(extracted_fields)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "480e26bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Alice', 'age': 25}, {'name': 'Bob', 'age': 30}]\n"
     ]
    }
   ],
   "source": [
    "with open('./sample_json.json', 'r') as f:\n",
    "    json_string = f.read()\n",
    "result = extract_fields(json_string, field_names)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ea690a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def extract_fields_from_json_file(file_path, field_names):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    result = []\n",
    "    for item in data:\n",
    "        extracted_fields = {}\n",
    "        for field_name in field_names:\n",
    "            if field_name in item:\n",
    "                extracted_fields[field_name] = item[field_name]\n",
    "        result.append(extracted_fields)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "934d93f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Alice', 'age': 25}, {'name': 'Bob', 'age': 30}]\n"
     ]
    }
   ],
   "source": [
    "file_path = './sample_json.json'\n",
    "field_names = ['name', 'age']\n",
    "result = extract_fields_from_json_file(file_path, field_names)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079fdd44",
   "metadata": {},
   "source": [
    "##  function to extract all the mentions from a string (i.e., all the Twitter usernames starting with '@')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4db3a871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_mentions(text):\n",
    "    return re.findall(r'@(\\w+)', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "50601412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['johndoe', 'janedoe', 'johndoe']\n"
     ]
    }
   ],
   "source": [
    "text = \"Just saw @johndoe and @janedoe at the coffee shop. @johndoe makes the best coffee!\"\n",
    "mentions = extract_mentions(text)\n",
    "print(mentions)  # Output: ['johndoe', 'janedoe', 'johndoe']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cfccee",
   "metadata": {},
   "source": [
    "## Python program that reads a log file and extracts the number of requests per hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "23a8ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1575dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_requests_per_hour(log_file):\n",
    "    with open(log_file, 'r') as f:\n",
    "        requests_per_hr = defaultdict(int)\n",
    "        \n",
    "        for line in f:\n",
    "            pattern = re.search(r'\\[(\\d{2})\\/(\\w{3})\\/(\\d{4}):(\\d{2}):\\d{2}:\\d{2}', line)\n",
    "            if pattern:\n",
    "                hour = pattern.group(4)\n",
    "                \n",
    "                requests_per_hr[hour]+=1\n",
    "                \n",
    "        for hour, count in sorted(requests_per_hr.items()):\n",
    "            print(f'hour: {hour} : {count}')\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d09274a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour: 12 : 2\n",
      "hour: 13 : 2\n",
      "hour: 14 : 1\n"
     ]
    }
   ],
   "source": [
    "log_file = './log.txt'\n",
    "extract_requests_per_hour(log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6b8cd3",
   "metadata": {},
   "source": [
    "## Write a program to extract all the text from a Microsoft Word document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f9c8a81f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import docx2txt\n",
    "\n",
    "def extract_text_from_docx(file_path):\n",
    "    # load the document\n",
    "    text = docx2txt.process(file_path)\n",
    "\n",
    "    # return the extracted text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "318d62a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N/AManasa Shivarudra\\n\\n\\n\\n\\t\\tmanasa.shivarudra@gmail.com\\t8067301117\\thttps://www.linkedin.com/in/manasa-shivarudra/      https://github.com/Manasa-Shivarudra\\n\\n\\n\\nSummary\\n\\n\\tSelf-taught Data Science and Machine Learning enthusiast seeking full time opportunities in Data Science and Machine Learning field. Independent and self-motivated software professional with 5 years’ experience working directly with the customer to build their outbound IVR applications in different channels. Worked as the Technical Lead for a 3-year implementation project which involved migration of 250 applications.\\n\\nSkills\\n\\n\\tPython, Scikit- Learn, Pandas, Numpy, Seaborn, TensorFlow, pytorch, pyspark, BERT, Scala, Azure, Linear Regression, Logistic Regression, NLP, SVM, K- means, Decision Trees, Random Forest, ANN, EDA, Data Visualization, Statistics, SQLite, SQL Server, Mongo DB/Atlas, Kubernetes, Apache Spark, Git\\n\\n\\t\\n\\nCertifications\\n\\nMicrosoft: Azure Fundamentals, Azure Data Fundamentals, Azure AI Fundamentals, Azure AI Engineer Associate\\n\\nExperience\\n\\nMachine Learning Engineer | Omdena AI | June 2021 - July 2022\\n\\n\\tCollaborated on the end-to-end Machine Learning project to build a model to predict the Energy consumption in a building which involved data.\\n\\n\\tprocessing, EDA, data visualization, feature engineering, model building and deployment on Azure ML Studio.\\n\\n\\tDeployed the model in Azure machine learning studio by creating a real-time endpoints and inference pipelines.\\n\\n\\tDesigned and implemented various machine learning algorithms like Boosted Decision Trees, Random Forest, Support Vector Machine and Artificial Neural Networks.\\n\\nSoftware Engineer/Tech Lead | Nuance Communications Inc | NJ, USA and Mississauga, Canada | October 2017 - October 2021\\n\\n\\tInvolved in customizing the IVR product based on complex client requirements. \\n\\n\\tBuilt high volume Conversational AI apps using Nuance proprietary SDK and Nuance Voice Platform\\n\\n\\tDeveloped robust Conversational AI applications on the voice platform for various top brands with 10% improvement in the application performance on the new platform. \\n\\n\\tMentoring junior and offshore developers on a large-scale migration project in Scala framework which involved reviewing the Scala code and providing feedback on best practices, improving performance etc. \\n\\n\\tCreated high-level Technical Design Documents for more than 100 applications. \\n\\n\\tWorked as the Technical Lead for a 3-year implementation project which involved redesigning of 250 applications on the new platform from legacy framework.\\n\\n\\tNuance Spot Award 2019 in recognition of going above and beyond for my hard work and contribution.\\n\\n\\tNuance Team Player Award June 2019 in keeping the migration project on track. \\n\\n\\tNuance Special Program Bonus October 2019 in recognition of hard work.\\n\\n\\n\\nTechnical Analyst | Trizetto Healthcare Solutions | Arizona, USA | February 2017 - August 2017\\n\\n\\tWorked on a health care product - Encounter Data Manager which is involved in creation of 837 files for claim submits.\\n\\n\\tInvolved in the customization and maintenance of the product based on the business needs of the user.\\n\\n\\t\\n\\nNew York Life Insurance Company- Object Oriented Intern | Dallas, TX | June 2016 - August 2016\\n\\n\\tDeveloped a Java application for treasury systems using MVC framework and DB2 for trade data transactions.\\n\\n\\tUsed TFS (Team Foundation Server) for source code management.\\n\\n\\tAdhered to the agile (SCRUM) methodologies of software development life cycle which involved all the phases of SDLC. \\n\\n\\n\\nTechnical Analyst | Oracle Financial Services Software Ltd | Bangalore, India | October 2012 - December 2014\\n\\n\\tDelivered bug fixes for the product FLEXCUBE to Bank’s across geographies, many of which were base lined.\\t         \\n\\n\\tEngaged in the product customization for consumer lending which included both the UI and Database changes (PL/SQL).\\n\\n\\tCollaborated with Banks like Chase, Diamond trust Bank and coordinated to satisfy their requirements.\\n\\n\\n\\nProjects\\n\\nTweet Emotion Recognition with TensorFlow (Hugging Face Data)\\n\\n\\tBuilt a Recurrent Neural Network for multi class classification of 6 emotions to train tweet emotion dataset to learn to recognize emotions in tweets. The model performed with a training accuracy of 98.56% and validation accuracy of 88.35% with 7 epochs using TensorFlow.\\n\\nTelecom Customers Churn Prediction\\n\\n\\tImplemented various classification models like Logistic Regression, SVM, KNN, Random Forest Classifier to predict the churn rate of telecommunication customers with an f1-score of 83% and an accuracy of 82%. Models were validated using the AUROC and ROC curves.\\n\\nBank Personal Loan Acceptance Prediction\\n\\n\\tBuilt a simple multilayer neural network model for predicting the probability of customers accepting the Personal Loan. Trained the model with ANN with a training accuracy of 99.19% and a test accuracy of 98%.\\n\\nEducation\\n\\nMasters in Computer Science | Texas Tech University | 3.6 | Texas, USA | 2016 \\n\\nBachelors of Engineering in Computer Science | Visvesvaraya Technological University | 3.8 | Karnataka, India | 2012'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_text_from_docx('./Manasa_shivarudra_CV.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17779da3",
   "metadata": {},
   "source": [
    "## Given a string of text, write a program to extract the most commonly occurring words in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d01a12d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def extract_common_words(corpus, count_words):\n",
    "    words = re.findall(r'\\b\\w+\\b', corpus.lower())\n",
    "    word_count = Counter(words)\n",
    "    \n",
    "    return word_count.most_common(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "64b29314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 13),\n",
       " ('and', 21),\n",
       " ('data', 9),\n",
       " ('for', 13),\n",
       " ('in', 17),\n",
       " ('of', 20),\n",
       " ('on', 11),\n",
       " ('the', 28),\n",
       " ('to', 11),\n",
       " ('with', 10)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = 'N/AManasa Shivarudra\\n\\n\\n\\n\\t\\tmanasa.shivarudra@gmail.com\\t8067301117\\thttps://www.linkedin.com/in/manasa-shivarudra/      https://github.com/Manasa-Shivarudra\\n\\n\\n\\nSummary\\n\\n\\tSelf-taught Data Science and Machine Learning enthusiast seeking full time opportunities in Data Science and Machine Learning field. Independent and self-motivated software professional with 5 years’ experience working directly with the customer to build their outbound IVR applications in different channels. Worked as the Technical Lead for a 3-year implementation project which involved migration of 250 applications.\\n\\nSkills\\n\\n\\tPython, Scikit- Learn, Pandas, Numpy, Seaborn, TensorFlow, pytorch, pyspark, BERT, Scala, Azure, Linear Regression, Logistic Regression, NLP, SVM, K- means, Decision Trees, Random Forest, ANN, EDA, Data Visualization, Statistics, SQLite, SQL Server, Mongo DB/Atlas, Kubernetes, Apache Spark, Git\\n\\n\\t\\n\\nCertifications\\n\\nMicrosoft: Azure Fundamentals, Azure Data Fundamentals, Azure AI Fundamentals, Azure AI Engineer Associate\\n\\nExperience\\n\\nMachine Learning Engineer | Omdena AI | June 2021 - July 2022\\n\\n\\tCollaborated on the end-to-end Machine Learning project to build a model to predict the Energy consumption in a building which involved data.\\n\\n\\tprocessing, EDA, data visualization, feature engineering, model building and deployment on Azure ML Studio.\\n\\n\\tDeployed the model in Azure machine learning studio by creating a real-time endpoints and inference pipelines.\\n\\n\\tDesigned and implemented various machine learning algorithms like Boosted Decision Trees, Random Forest, Support Vector Machine and Artificial Neural Networks.\\n\\nSoftware Engineer/Tech Lead | Nuance Communications Inc | NJ, USA and Mississauga, Canada | October 2017 - October 2021\\n\\n\\tInvolved in customizing the IVR product based on complex client requirements. \\n\\n\\tBuilt high volume Conversational AI apps using Nuance proprietary SDK and Nuance Voice Platform\\n\\n\\tDeveloped robust Conversational AI applications on the voice platform for various top brands with 10% improvement in the application performance on the new platform. \\n\\n\\tMentoring junior and offshore developers on a large-scale migration project in Scala framework which involved reviewing the Scala code and providing feedback on best practices, improving performance etc. \\n\\n\\tCreated high-level Technical Design Documents for more than 100 applications. \\n\\n\\tWorked as the Technical Lead for a 3-year implementation project which involved redesigning of 250 applications on the new platform from legacy framework.\\n\\n\\tNuance Spot Award 2019 in recognition of going above and beyond for my hard work and contribution.\\n\\n\\tNuance Team Player Award June 2019 in keeping the migration project on track. \\n\\n\\tNuance Special Program Bonus October 2019 in recognition of hard work.\\n\\n\\n\\nTechnical Analyst | Trizetto Healthcare Solutions | Arizona, USA | February 2017 - August 2017\\n\\n\\tWorked on a health care product - Encounter Data Manager which is involved in creation of 837 files for claim submits.\\n\\n\\tInvolved in the customization and maintenance of the product based on the business needs of the user.\\n\\n\\t\\n\\nNew York Life Insurance Company- Object Oriented Intern | Dallas, TX | June 2016 - August 2016\\n\\n\\tDeveloped a Java application for treasury systems using MVC framework and DB2 for trade data transactions.\\n\\n\\tUsed TFS (Team Foundation Server) for source code management.\\n\\n\\tAdhered to the agile (SCRUM) methodologies of software development life cycle which involved all the phases of SDLC. \\n\\n\\n\\nTechnical Analyst | Oracle Financial Services Software Ltd | Bangalore, India | October 2012 - December 2014\\n\\n\\tDelivered bug fixes for the product FLEXCUBE to Bank’s across geographies, many of which were base lined.\\t         \\n\\n\\tEngaged in the product customization for consumer lending which included both the UI and Database changes (PL/SQL).\\n\\n\\tCollaborated with Banks like Chase, Diamond trust Bank and coordinated to satisfy their requirements.\\n\\n\\n\\nProjects\\n\\nTweet Emotion Recognition with TensorFlow (Hugging Face Data)\\n\\n\\tBuilt a Recurrent Neural Network for multi class classification of 6 emotions to train tweet emotion dataset to learn to recognize emotions in tweets. The model performed with a training accuracy of 98.56% and validation accuracy of 88.35% with 7 epochs using TensorFlow.\\n\\nTelecom Customers Churn Prediction\\n\\n\\tImplemented various classification models like Logistic Regression, SVM, KNN, Random Forest Classifier to predict the churn rate of telecommunication customers with an f1-score of 83% and an accuracy of 82%. Models were validated using the AUROC and ROC curves.\\n\\nBank Personal Loan Acceptance Prediction\\n\\n\\tBuilt a simple multilayer neural network model for predicting the probability of customers accepting the Personal Loan. Trained the model with ANN with a training accuracy of 99.19% and a test accuracy of 98%.\\n\\nEducation\\n\\nMasters in Computer Science | Texas Tech University | 3.6 | Texas, USA | 2016 \\n\\nBachelors of Engineering in Computer Science | Visvesvaraya Technological University | 3.8 | Karnataka, India | 2012'\n",
    "sorted(extract_common_words(corpus, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41534263",
   "metadata": {},
   "source": [
    "## Given a large dataset of text documents, write a program to extract the most commonly occurring words across all the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "269a1446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def extract_commonwords_doc(data_dir, num_words):\n",
    "    word_count = Counter()\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        file_path = os.path.join(data_dir, file_name)\n",
    "\n",
    "        with open(file_path, 'r', encoding = 'utf-8') as f:\n",
    "            text = f.read()\n",
    "            words = text.split() \n",
    "            word_count.update(words)\n",
    "    return word_count.most_common(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a974ea66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('-', 9), ('for', 5), ('me', 5), ('a', 4), ('Subject:', 3), ('To:', 3), ('From:', 3), ('Hi', 3), ('of', 3), ('if', 3)]\n"
     ]
    }
   ],
   "source": [
    "data_dir = './EmailDirectory/'\n",
    "num_words = 10\n",
    "common_words= extract_common_words(data_dir, num_words)\n",
    "print(common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d40f78",
   "metadata": {},
   "source": [
    "## Write an optimized program to extract all the named entities from a text document, such as people, organizations, and locations using NLTK library with time and space complexity\n",
    "\n",
    "The time complexity of this approach is O(n^2) in the worst case, where n is the number of sentences in the text. The space complexity of this approach depends on the size of the text and the number of named entities in it. The space complexity could be large if the text contains many named entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b1252c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c7e47ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_named_entities(text):\n",
    "    sentences = nltk.sent_tokenize(text) #tokenize the text\n",
    "    tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "    tagged_sentences = [nltk.pos_tag(sentence) for sentence in tokenized_sentences]\n",
    "    \n",
    "    named_entities=[]\n",
    "    for sentence in tagged_sentences:\n",
    "        tree= nltk.ne_chunk(sentence)\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() in ['PERSON', 'ORGANIZATION', 'GPE']:\n",
    "                named_entity = \" \".join([token for token, pos in subtree.leaves()])\n",
    "                named_entities.append((named_entity, subtree.label()))\n",
    "    \n",
    "    return named_entities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "26dfaf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('United States', 'GPE'), ('America', 'GPE'), ('USA', 'ORGANIZATION'), ('United States', 'GPE'), ('U.S.', 'GPE'), ('US', 'GPE'), ('America', 'GPE'), ('North America', 'GPE'), ('Indian', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "text = \"The United States of America (USA), commonly known as the United States (U.S. or US) or America, is a country primarily located in North America. It consists of 50 states, a federal district, five major self-governing territories, 326 Indian reservations, and some minor possessions. At 3.8 million square miles (9.8 million square kilometers), it is the world's third- or fourth-largest country by total area. With a population of over 328 million, it is the third most populous country in the world.\"\n",
    "named_entities= extract_named_entities(text)\n",
    "print(named_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3418ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## same program using spacy\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "90482c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_named_entity_spacy(text):\n",
    "    spacy.cli.download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    named_entities=[]\n",
    "    for entity in doc.ents:\n",
    "        if entity.label_ in ['PERSON', 'ORG', 'GPE']:\n",
    "            named_entities.append((entity.text, entity.label_))\n",
    "    \n",
    "    return named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "36de5083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "[('The United States of America', 'GPE'), ('USA', 'GPE'), ('the United States', 'GPE'), ('U.S.', 'GPE'), ('US', 'GPE'), ('America', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "text = \"The United States of America (USA), commonly known as the United States (U.S. or US) or America, is a country primarily located in North America. It consists of 50 states, a federal district, five major self-governing territories, 326 Indian reservations, and some minor possessions. At 3.8 million square miles (9.8 million square kilometers), it is the world's third- or fourth-largest country by total area. With a population of over 328 million, it is the third most populous country in the world.\"\n",
    "named_entities= extract_named_entity_spacy(text)\n",
    "print(named_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf1565d",
   "metadata": {},
   "source": [
    "## Write a program to extract all the synonyms for a given word from an online thesaurus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b7f9b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_synonyms(word):\n",
    "    url = f'https://api.dictionaryapi.dev/api/v2/entries/en/{word}'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        meanings = data[0]['meanings']\n",
    "        \n",
    "        synonyms = []\n",
    "        for meaning in meanings:\n",
    "            if 'synonyms' in meaning:\n",
    "                for synonym in meaning['synonyms']:\n",
    "                    synonyms.append(synonym)\n",
    "        \n",
    "        return synonyms\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "8bb80612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happify', 'cheerful', 'content', 'delighted', 'elated', 'exultant', 'glad', 'joyful', 'jubilant', 'merry', 'orgasmic', 'fortunate', 'lucky', 'propitious']\n"
     ]
    }
   ],
   "source": [
    "synonyms = get_synonyms('happy')\n",
    "print(synonyms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff131b4",
   "metadata": {},
   "source": [
    "## Given a text document, write a program to extract the topics or themes of the document using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d0cb612a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\manas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses the input text by tokenizing it into words, removing stop words, \n",
    "    and returning a preprocessed string.\n",
    "    \"\"\"\n",
    "    # Tokenize text into words\n",
    "    words = text.lower().split()\n",
    "    \n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Join words back into a string\n",
    "    preprocessed_text = \" \".join(words)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "def extract_topics_sklearn(text, num_topics=5):\n",
    "    \"\"\"\n",
    "    Extracts topics from the input text using the LDA algorithm.\n",
    "    Returns a list of tuples, where each tuple represents a topic and its associated words.\n",
    "    \"\"\"\n",
    "    # Preprocess text\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    \n",
    "    # Create a count vectorizer\n",
    "    count_vectorizer = CountVectorizer(stop_words='english')\n",
    "    \n",
    "    # Fit the count vectorizer to the preprocessed text\n",
    "    count_vectorizer.fit_transform([preprocessed_text])\n",
    "    \n",
    "    # Create an LDA model\n",
    "    lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "    \n",
    "    # Fit the LDA model to the count vectorizer\n",
    "    lda.fit(count_vectorizer.transform([preprocessed_text]))\n",
    "    \n",
    "    # Get the top words for each topic\n",
    "    feature_names = count_vectorizer.get_feature_names_out()\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-11:-1]]\n",
    "        topics.append((topic_idx, top_words))\n",
    "    \n",
    "    return topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "08262cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, ['language', 'like', 'nlp', 'text', 'analysis', 'learning', 'translation', 'tasks', 'techniques', 'machine']), (1, ['years', 'need', 'generation', 'goal', 'important', 'include', 'increasingly', 'information', 'insights', 'interact']), (2, ['years', 'need', 'generation', 'goal', 'important', 'include', 'increasingly', 'information', 'insights', 'interact']), (3, ['years', 'need', 'generation', 'goal', 'important', 'include', 'increasingly', 'information', 'insights', 'interact']), (4, ['years', 'need', 'generation', 'goal', 'important', 'include', 'increasingly', 'information', 'insights', 'interact'])]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Natural Language Processing (NLP) is a field of study that focuses on the interaction between computers and human language. The goal of NLP is to enable computers to understand, interpret, and generate human language in a way that is useful for various applications such as language translation, sentiment analysis, and chatbots.\n",
    "\n",
    "NLP involves a variety of techniques such as text preprocessing, machine learning, and deep learning. Preprocessing involves tasks like tokenization, stopword removal, stemming, and lemmatization to clean and prepare the text data for further analysis. Machine learning techniques like Naive Bayes, Support Vector Machines (SVM), and Random Forests are commonly used for tasks like sentiment analysis, text classification, and named entity recognition. Deep learning techniques like Recurrent Neural Networks (RNNs), Convolutional Neural Networks (CNNs), and Transformers are used for more complex tasks like language modeling, machine translation, and text generation.\n",
    "\n",
    "NLP has become increasingly important in recent years with the explosion of digital data and the need to extract insights and information from unstructured text data. The applications of NLP are wide-ranging and include sentiment analysis for social media monitoring, chatbots for customer service, language translation for international business, and speech recognition for personal assistants like Siri and Alexa. As the field of NLP continues to evolve, it has the potential to transform the way we interact with computers and each other through natural language.\"\"\"\n",
    "topics = extract_topics_sklearn(text)\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c57e5b",
   "metadata": {},
   "source": [
    "## Given a text document, write a program to extract the topics or themes of the document using gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "0d743207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\manas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses the input text by tokenizing it into words, removing stop words, \n",
    "    and returning a preprocessed string.\n",
    "    \"\"\"\n",
    "    # Tokenize text into words\n",
    "    words = text.lower().split()\n",
    "    \n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Create a dictionary from the words\n",
    "    dictionary = corpora.Dictionary([words])\n",
    "    \n",
    "    # Create a corpus from the dictionary\n",
    "    corpus = [dictionary.doc2bow([word]) for word in words]\n",
    "    \n",
    "    return corpus, dictionary\n",
    "\n",
    "def extract_topics(text, num_topics=5):\n",
    "    \"\"\"\n",
    "    Extracts topics from the input text using the LDA algorithm.\n",
    "    Returns a list of tuples, where each tuple represents a topic and its associated words.\n",
    "    \"\"\"\n",
    "    # Preprocess text\n",
    "    corpus, dictionary = preprocess_text(text)\n",
    "    \n",
    "    # Create an LDA model\n",
    "    lda = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "    \n",
    "    # Get the top words for each topic\n",
    "    topics = []\n",
    "    for topic_idx, topic in lda.show_topics(num_topics=num_topics, num_words=10, formatted=False):\n",
    "        top_words = [word[0] for word in topic]\n",
    "        topics.append((topic_idx, top_words))\n",
    "    \n",
    "    return topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "fb87fe06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, ['nlp', 'machine', 'text', 'human', 'international', 'entity', 'continues', 'potential', 'alexa.', 'speech']), (1, ['language', 'nlp', 'analysis,', 'data', 'way', 'like', 'applications', 'translation,', 'study', 'increasingly']), (2, ['text', 'language.', 'natural', 'techniques', 'learning', 'wide-ranging', 'neural', 'networks', 'applications', 'bayes,']), (3, ['sentiment', 'computers', 'involves', 'field', 'support', '(svm),', 'chatbots', 'complex', 'variety', 'translation,']), (4, ['like', 'tasks', 'techniques', 'deep', 'used', 'learning', 'networks', 'human', 'neural', 'assistants'])]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Natural Language Processing (NLP) is a field of study that focuses on the interaction between computers and human language. The goal of NLP is to enable computers to understand, interpret, and generate human language in a way that is useful for various applications such as language translation, sentiment analysis, and chatbots.\n",
    "\n",
    "NLP involves a variety of techniques such as text preprocessing, machine learning, and deep learning. Preprocessing involves tasks like tokenization, stopword removal, stemming, and lemmatization to clean and prepare the text data for further analysis. Machine learning techniques like Naive Bayes, Support Vector Machines (SVM), and Random Forests are commonly used for tasks like sentiment analysis, text classification, and named entity recognition. Deep learning techniques like Recurrent Neural Networks (RNNs), Convolutional Neural Networks (CNNs), and Transformers are used for more complex tasks like language modeling, machine translation, and text generation.\n",
    "\n",
    "NLP has become increasingly important in recent years with the explosion of digital data and the need to extract insights and information from unstructured text data. The applications of NLP are wide-ranging and include sentiment analysis for social media monitoring, chatbots for customer service, language translation for international business, and speech recognition for personal assistants like Siri and Alexa. As the field of NLP continues to evolve, it has the potential to transform the way we interact with computers and each other through natural language.\"\"\"\n",
    "topics = extract_topics(text)\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35368996",
   "metadata": {},
   "source": [
    "## Given a text document, write an optimized python program to extract the topics or themes of the document using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "2f41571f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\manas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\manas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\manas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\manas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import FreqDist\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from gensim import corpora, models\n",
    "\n",
    "# Download necessary NLTK packages\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses the input text by tokenizing it into words, removing stop words, \n",
    "    lemmatizing the words, and returning a preprocessed string.\n",
    "    \"\"\"\n",
    "    # Tokenize text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if not word.lower() in stop_words]\n",
    "    \n",
    "    # Lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in words]\n",
    "    \n",
    "    # Join the words back into a string\n",
    "    preprocessed_text = ' '.join(words)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"\n",
    "    Map POS tag to first character used by WordNetLemmatizer.\n",
    "    \"\"\"\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wn.ADJ,\n",
    "                \"N\": wn.NOUN,\n",
    "                \"V\": wn.VERB,\n",
    "                \"R\": wn.ADV}\n",
    "    return tag_dict.get(tag, wn.NOUN)\n",
    "\n",
    "def extract_topics_nltk(text, num_topics=5):\n",
    "    \"\"\"\n",
    "    Extracts topics from the input text using the LDA algorithm from Gensim library.\n",
    "    \"\"\"\n",
    "    # Preprocess the text\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    \n",
    "    # Tokenize the preprocessed text\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(preprocessed_text)\n",
    "    \n",
    "    # Create a bag of words from the tokens\n",
    "    bag_of_words = FreqDist(tokens)\n",
    "    \n",
    "    # Create a list of the most common words\n",
    "    most_common_words = [word for word, count in bag_of_words.most_common(50)]\n",
    "    \n",
    "    # Remove the most common words from the bag of words\n",
    "    filtered_bag_of_words = {word:count for word, count in bag_of_words.items() if word not in most_common_words}\n",
    "    \n",
    "    # Create a corpus from the filtered bag of words\n",
    "    corpus = []\n",
    "    for word, count in filtered_bag_of_words.items():\n",
    "        corpus.append([word] * count)\n",
    "    \n",
    "    # Create a dictionary from the corpus\n",
    "    dictionary = corpora.Dictionary(corpus)\n",
    "    \n",
    "    # Create a document-term matrix from the corpus and dictionary\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in corpus]\n",
    "    \n",
    "    # Train the LDA model\n",
    "    lda_model = models.ldamodel.LdaModel(doc_term_matrix, num_topics=num_topics, id2word=dictionary)\n",
    "    \n",
    "    # Extract the topics from the LDA model\n",
    "    topics = lda_model.show_topics(num_topics=num_topics, num_words=10, formatted=False)\n",
    "    \n",
    "    return topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "fa51aa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, [('extract', 0.037028715), ('Recurrent', 0.03645307), ('evolve', 0.036421407), ('Random', 0.03632566), ('model', 0.03554333), ('digital', 0.034580395), ('natural', 0.03456814), ('social', 0.03431792), ('name', 0.034242976), ('complex', 0.033465277)]), (1, [('potential', 0.034049515), ('explosion', 0.03279551), ('international', 0.032790456), ('medium', 0.03258431), ('personal', 0.0324477), ('commonly', 0.032179188), ('classification', 0.032178752), ('entity', 0.031956233), ('include', 0.03186875), ('important', 0.031829584)]), (2, [('wide', 0.035317622), ('speech', 0.03491443), ('recent', 0.034565855), ('Transformers', 0.03419726), ('continue', 0.033830557), ('Deep', 0.033496328), ('Vector', 0.03313662), ('year', 0.033101015), ('Support', 0.033037666), ('customer', 0.032932263)])]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Natural Language Processing (NLP) is a field of study that focuses on the interaction between computers and human language. The goal of NLP is to enable computers to understand, interpret, and generate human language in a way that is useful for various applications such as language translation, sentiment analysis, and chatbots.\n",
    "\n",
    "NLP involves a variety of techniques such as text preprocessing, machine learning, and deep learning. Preprocessing involves tasks like tokenization, stopword removal, stemming, and lemmatization to clean and prepare the text data for further analysis. Machine learning techniques like Naive Bayes, Support Vector Machines (SVM), and Random Forests are commonly used for tasks like sentiment analysis, text classification, and named entity recognition. Deep learning techniques like Recurrent Neural Networks (RNNs), Convolutional Neural Networks (CNNs), and Transformers are used for more complex tasks like language modeling, machine translation, and text generation.\n",
    "\n",
    "NLP has become increasingly important in recent years with the explosion of digital data and the need to extract insights and information from unstructured text data. The applications of NLP are wide-ranging and include sentiment analysis for social media monitoring, chatbots for customer service, language translation for international business, and speech recognition for personal assistants like Siri and Alexa. As the field of NLP continues to evolve, it has the potential to transform the way we interact with computers and each other through natural language.\"\"\"\n",
    "topics = extract_topics_nltk(text, 3)\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e50638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
